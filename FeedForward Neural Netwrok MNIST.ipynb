{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmArqWJIIcSh"
      },
      "source": [
        "Used MNIST dataset to do the following:\n",
        "\n",
        "Create a Feed Forward Neural Network where\n",
        "\n",
        "• Input layer has 784 nodes and output layer have appropriate number of node(10)\n",
        "\n",
        "• Used Multiclass Cross Entropy loss function, Stochastic Gradient\n",
        "descent(SGD) optimizer and random weight initialization techniques\n",
        "to train the model.\n",
        "\n",
        "• Reported all the hyperparameters that you have assumed like batch size,learning rate etc.\n",
        "\n",
        "• Plotted epoch wise training loss and Reported testing accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo8_znU5VsGS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "import sys\n",
        "import pickle as cPickle\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from keras import initializers\n",
        "from keras import optimizers\n",
        "from matplotlib import pyplot\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from array import array\n",
        "\n",
        "#Q2\n",
        "#unpacking the images\n",
        "def images_file_read(file_name):\n",
        "    with gzip.open(file_name, 'r') as f:\n",
        "        magic_number = int.from_bytes(f.read(4), 'big')\n",
        "        image_count = int.from_bytes(f.read(4), 'big')\n",
        "        row_count = int.from_bytes(f.read(4), 'big')\n",
        "        column_count = int.from_bytes(f.read(4), 'big')\n",
        "\n",
        "        image_data = f.read()\n",
        "        images = np.frombuffer(image_data, dtype=np.uint8)\\\n",
        "            .reshape((image_count, row_count, column_count))\n",
        "        return images\n",
        "\n",
        "def labels_file_read(file_name):\n",
        "    with gzip.open(file_name, 'r') as f:\n",
        "        magic_number = int.from_bytes(f.read(4), 'big')\n",
        "        label_count = int.from_bytes(f.read(4), 'big')\n",
        "        label_data = f.read()\n",
        "        labels = np.frombuffer(label_data, dtype=np.uint8)\n",
        "        return labels\n",
        "\n",
        "train_images = images_file_read(\"/content/drive/MyDrive/train-images-idx3-ubyte.gz\")\n",
        "train_labels = labels_file_read(\"/content/drive/MyDrive/train-labels-idx1-ubyte.gz\")\n",
        "test_imagesall = images_file_read(\"/content/drive/MyDrive/t10k-images-idx3-ubyte.gz\")\n",
        "test_labelsall = labels_file_read(\"/content/drive/MyDrive/t10k-labels-idx1-ubyte.gz\")\n",
        "\n",
        "\n",
        "# dividing into validation set and test set\n",
        "val_images = test_imagesall[0:500,:,:]\n",
        "val_labels = test_labelsall[0:500]\n",
        "test_images = test_imagesall[500:,:,:]\n",
        "test_labels = test_labelsall[500:]\n",
        "\n",
        "#normalizing images\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "val_images = (val_images / 255) - 0.5\n",
        "\n",
        "#flatening the images\n",
        "train_images = train_images.reshape((-1, 784))\n",
        "test_images = test_images.reshape((-1, 784))\n",
        "val_images = val_images.reshape((-1, 784))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mBchp16d2pW",
        "outputId": "06fa432c-288a-4ef7-ec46-12b44c86d416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_81 (Dense)            (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 32)                0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,095,866\n",
            "Trainable params: 1,094,778\n",
            "Non-trainable params: 1,088\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(784, input_dim=784))  #input layer\n",
        "\n",
        "#Hidden Layers\n",
        "model.add(Dense(512, input_dim=784, trainable=True,activation='relu', use_bias=True, kernel_initializer='random_normal', bias_initializer='zeros')) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(10, trainable=True, activation='softmax')) # output layer\n",
        "\n",
        "#optimizer\n",
        "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFONc_VYe9B8",
        "outputId": "514e0a86-d83b-4704-8fe6-f647e31b7212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.9127 - accuracy: 0.7419\n",
            "Epoch 1: val_accuracy improved from -inf to 0.91600, saving model to best_model.h5\n",
            "118/118 [==============================] - 9s 66ms/step - loss: 0.9118 - accuracy: 0.7422 - val_loss: 0.4742 - val_accuracy: 0.9160\n",
            "Epoch 2/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.3356 - accuracy: 0.9061\n",
            "Epoch 2: val_accuracy improved from 0.91600 to 0.93800, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.3355 - accuracy: 0.9062 - val_loss: 0.5385 - val_accuracy: 0.9380\n",
            "Epoch 3/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9278\n",
            "Epoch 3: val_accuracy improved from 0.93800 to 0.94400, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.2479 - accuracy: 0.9278 - val_loss: 0.4357 - val_accuracy: 0.9440\n",
            "Epoch 4/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9399\n",
            "Epoch 4: val_accuracy did not improve from 0.94400\n",
            "118/118 [==============================] - 9s 73ms/step - loss: 0.2073 - accuracy: 0.9399 - val_loss: 0.3578 - val_accuracy: 0.9420\n",
            "Epoch 5/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1829 - accuracy: 0.9465\n",
            "Epoch 5: val_accuracy improved from 0.94400 to 0.95200, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 61ms/step - loss: 0.1830 - accuracy: 0.9464 - val_loss: 0.3277 - val_accuracy: 0.9520\n",
            "Epoch 6/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1670 - accuracy: 0.9504\n",
            "Epoch 6: val_accuracy improved from 0.95200 to 0.96200, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 61ms/step - loss: 0.1669 - accuracy: 0.9504 - val_loss: 0.2371 - val_accuracy: 0.9620\n",
            "Epoch 7/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9547\n",
            "Epoch 7: val_accuracy did not improve from 0.96200\n",
            "118/118 [==============================] - 7s 61ms/step - loss: 0.1529 - accuracy: 0.9547 - val_loss: 0.2247 - val_accuracy: 0.9500\n",
            "Epoch 8/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1384 - accuracy: 0.9589\n",
            "Epoch 8: val_accuracy improved from 0.96200 to 0.96600, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.1384 - accuracy: 0.9589 - val_loss: 0.1934 - val_accuracy: 0.9660\n",
            "Epoch 9/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9619\n",
            "Epoch 9: val_accuracy improved from 0.96600 to 0.97000, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.1289 - accuracy: 0.9619 - val_loss: 0.1806 - val_accuracy: 0.9700\n",
            "Epoch 10/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9636\n",
            "Epoch 10: val_accuracy improved from 0.97000 to 0.97800, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.1222 - accuracy: 0.9635 - val_loss: 0.1354 - val_accuracy: 0.9780\n",
            "Epoch 11/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9654\n",
            "Epoch 11: val_accuracy did not improve from 0.97800\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.1146 - accuracy: 0.9654 - val_loss: 0.1159 - val_accuracy: 0.9780\n",
            "Epoch 12/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9678\n",
            "Epoch 12: val_accuracy did not improve from 0.97800\n",
            "118/118 [==============================] - 7s 61ms/step - loss: 0.1078 - accuracy: 0.9677 - val_loss: 0.1268 - val_accuracy: 0.9700\n",
            "Epoch 13/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9692\n",
            "Epoch 13: val_accuracy improved from 0.97800 to 0.98200, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.1029 - accuracy: 0.9692 - val_loss: 0.1063 - val_accuracy: 0.9820\n",
            "Epoch 14/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9701\n",
            "Epoch 14: val_accuracy did not improve from 0.98200\n",
            "118/118 [==============================] - 7s 61ms/step - loss: 0.0989 - accuracy: 0.9700 - val_loss: 0.1048 - val_accuracy: 0.9780\n",
            "Epoch 15/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9709\n",
            "Epoch 15: val_accuracy did not improve from 0.98200\n",
            "118/118 [==============================] - 7s 61ms/step - loss: 0.0943 - accuracy: 0.9709 - val_loss: 0.1033 - val_accuracy: 0.9800\n",
            "Epoch 16/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9711\n",
            "Epoch 16: val_accuracy did not improve from 0.98200\n",
            "118/118 [==============================] - 7s 61ms/step - loss: 0.0929 - accuracy: 0.9711 - val_loss: 0.1182 - val_accuracy: 0.9740\n",
            "Epoch 17/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0862 - accuracy: 0.9736\n",
            "Epoch 17: val_accuracy improved from 0.98200 to 0.98400, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0862 - accuracy: 0.9736 - val_loss: 0.0818 - val_accuracy: 0.9840\n",
            "Epoch 18/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9744\n",
            "Epoch 18: val_accuracy did not improve from 0.98400\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0825 - accuracy: 0.9743 - val_loss: 0.0829 - val_accuracy: 0.9820\n",
            "Epoch 19/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.9752\n",
            "Epoch 19: val_accuracy did not improve from 0.98400\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0792 - accuracy: 0.9752 - val_loss: 0.0863 - val_accuracy: 0.9760\n",
            "Epoch 20/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9766\n",
            "Epoch 20: val_accuracy did not improve from 0.98400\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0759 - accuracy: 0.9766 - val_loss: 0.0985 - val_accuracy: 0.9680\n",
            "Epoch 21/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9781\n",
            "Epoch 21: val_accuracy did not improve from 0.98400\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0719 - accuracy: 0.9781 - val_loss: 0.0909 - val_accuracy: 0.9700\n",
            "Epoch 22/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9783\n",
            "Epoch 22: val_accuracy improved from 0.98400 to 0.98600, saving model to best_model.h5\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0695 - accuracy: 0.9782 - val_loss: 0.0712 - val_accuracy: 0.9860\n",
            "Epoch 23/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9780\n",
            "Epoch 23: val_accuracy did not improve from 0.98600\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0712 - accuracy: 0.9779 - val_loss: 0.0860 - val_accuracy: 0.9800\n",
            "Epoch 24/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9786\n",
            "Epoch 24: val_accuracy did not improve from 0.98600\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0680 - accuracy: 0.9786 - val_loss: 0.0797 - val_accuracy: 0.9780\n",
            "Epoch 25/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9809\n",
            "Epoch 25: val_accuracy did not improve from 0.98600\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0625 - accuracy: 0.9808 - val_loss: 0.0700 - val_accuracy: 0.9840\n",
            "Epoch 26/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9794\n",
            "Epoch 26: val_accuracy did not improve from 0.98600\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0644 - accuracy: 0.9793 - val_loss: 0.0801 - val_accuracy: 0.9800\n",
            "Epoch 27/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9809\n",
            "Epoch 27: val_accuracy did not improve from 0.98600\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0625 - accuracy: 0.9808 - val_loss: 0.0772 - val_accuracy: 0.9800\n",
            "Epoch 28/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9805\n",
            "Epoch 28: val_accuracy did not improve from 0.98600\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0619 - accuracy: 0.9804 - val_loss: 0.0683 - val_accuracy: 0.9820\n",
            "Epoch 29/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9821\n",
            "Epoch 29: val_accuracy did not improve from 0.98600\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0576 - accuracy: 0.9821 - val_loss: 0.0750 - val_accuracy: 0.9800\n",
            "Epoch 30/30\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9817\n",
            "Epoch 30: val_accuracy did not improve from 0.98600\n",
            "118/118 [==============================] - 7s 61ms/step - loss: 0.0575 - accuracy: 0.9817 - val_loss: 0.0675 - val_accuracy: 0.9820\n"
          ]
        }
      ],
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "# Training the model.\n",
        "history=model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  validation_data=(val_images, to_categorical(val_labels)),  \n",
        "  epochs=15,\n",
        "  batch_size=512,\n",
        "  shuffle = True,\n",
        "  callbacks=[es,mc]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "KzSDeTUqfTVs",
        "outputId": "f67ddb8b-6f39-4ae6-939f-45ff711267c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 2s 5ms/step - loss: 0.0787 - accuracy: 0.9771\n",
            "Classwise Accuracy:\n",
            "Class  0  : 0.9850746268656716\n",
            "Class  1  : 0.9943820224719101\n",
            "Class  2  : 0.9723643807574207\n",
            "Class  3  : 0.9761658031088083\n",
            "Class  4  : 0.9697950377562028\n",
            "Class  5  : 0.9584323040380047\n",
            "Class  6  : 0.9879781420765027\n",
            "Class  7  : 0.9765066394279878\n",
            "Class  8  : 0.9657387580299786\n",
            "Class  9  : 0.9821989528795811\n",
            "Overall accuracy: 0.977052628993988\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluating the model.\n",
        "saved_model = load_model('best_model.h5')\n",
        "scores = saved_model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred=model.predict(test_images) \n",
        "y_pred=np.argmax(pred,axis=1)\n",
        "\n",
        "matrix = confusion_matrix(test_labels, y_pred)\n",
        "cwa=matrix.diagonal()/matrix.sum(axis=1)\n",
        "\n",
        "print(\"Classwise Accuracy:\")\n",
        "for i in range(0,10):\n",
        "  print(\"Class \",i,\" :\",cwa[i])\n",
        "\n",
        "print('Overall accuracy:', scores[1])\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "figure(figsize=(8, 6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0fr81uu-9nO"
      },
      "source": [
        "Test Accuracy: > 95%\n",
        "\n",
        "Hyper-Parameters assumed: \n",
        "*  Learning rate: 0.01\n",
        "*  Momentum: 0.9\n",
        "*  Epochs: 30\n",
        "*  Batch Size: 512\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SML_Assignment4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
